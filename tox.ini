[tox]
env_list = py{3.10,3.11,3.12}-ml,py{3.10,3.11,3.12}-verify-install

[gh-actions]
python =
    3.10: py3.10,py10-ml,py3.10-verify-install
    3.11: py3.11,py11-ml,py3.11-verify-install
    3.12: py3.12,py11-ml,py3.12-verify-install

[testenv]
set_env =
    PYTHONPATH = {toxinidir}
# HTTP_PROXY and HTTPS_PROXY are required behind corporate proxies
pass_env =
    DISPLAY
    XAUTHORITY
    HTTP_PROXY
    HTTPS_PROXY

[testenv:requirements]
base_python = python3.10
skip_install = true
deps =
    pip-tools
commands =
    # remove requirements-*.txt as otherwise the dependencies are not properly updated
    python -c 'import os; os.remove("requirements.txt")  if os.path.exists("requirements.txt") else None'
    python -c 'import os; os.remove("requirements-dev.txt")  if os.path.exists("requirements-dev.txt") else None'
    python -c 'import os; os.remove("requirements-ml.txt")  if os.path.exists("requirements-ml.txt") else None'
    python -m piptools compile -o requirements.txt pyproject.toml
    python -m piptools compile --extra dev -o requirements-dev.txt pyproject.toml
    python -m piptools compile --extra ml -o requirements-ml.txt pyproject.toml

[testenv:py{3.10,3.11,3.12}]
platform = linux|linux2|darwin
deps =
    -r requirements-dev.txt
set_env =
    BENCHMARK_EPISODES_FOLDER = {tox_root}/episodes
commands =
    python --version
    python -m pytest {posargs} --ignore=tests/ml

[testenv:py{3.10,3.11,3.12}-ml]
platform = linux|linux2|darwin
set_env =
    BENCHMARK_EPISODES_FOLDER = {tox_root}/episodes
deps =
    -r requirements-dev.txt
    -r requirements-ml.txt
commands =
    python --version
    python -m pytest --retries 2 --retry-delay 5 {posargs} tests/ml

[testenv:lint]
base_python = python3.10
skip_install = true
deps =
    -r requirements-dev.txt
commands =
    flake8 flatland tests examples benchmarks

[flake8]
exclude = docs
max-line-length = 120
ignore = E121 E126 E123 E128 E133 E226 E241 E242 E704 W291 W293 W391 W503 W504 W505


[testenv:coverage]
base_python = python3.10
skip_install = true
deps =
    -r requirements-dev.txt
commands =
    python scripts/make_coverage.py


[testenv:profiling]
base_python = python3.10
deps =
    -r requirements-dev.txt
set_env =
    PROFILING_OUTPUT_FOLDER = {work_dir}/{env_name}/log
    SCENARIOS_FOLDER = {tox_root}/scenarios
commands =
    python benchmarks/profile_all_examples.py

[testenv:py{3.10,3.11,3.12}-examples]
platform = linux|linux2|darwin
deps =
    -r requirements-dev.txt
set_env =
    SCENARIOS_FOLDER = {tox_root}/scenarios
commands =
    python --version
    python benchmarks/run_all_examples.py

[testenv:py{3.10,3.11,3.12}-notebooks]
platform = linux|linux2|darwin
allowlist_externals =
    bash
    pwd
deps =
    -r requirements-dev.txt
commands =
    python --version
    python -m pytest -s --nbmake  \
        notebooks/interactiveai.ipynb \
        notebooks/graph_demo.ipynb \
        notebooks/simple-graph-plot-2022.ipynb \
        notebooks/Agent-Close-Following.ipynb \
        notebooks/simple_example_manual_control.ipynb \
        notebooks/simple_rendering_demo.ipynb \
        notebooks/flatland_animate.ipynb \
        notebooks/render_episode.ipynb \
        notebooks/scene_editor.ipynb \
        notebooks/test_saved_envs.ipynb \
        notebooks/test_service.ipynb

[testenv:build]
base_python = python3.10
skip_install = true
deps =
    -r requirements-dev.txt
commands =
    python -m build

[testenv:py{3.10,3.11,3.12}-verify-install]
# install flatland-rl without additional dependencies
skip_install = false
commands =
    python --version
    python -c 'from flatland.evaluators.service import FlatlandRemoteEvaluationService'
    python -c 'import flatland.integrations.interactiveai.interactiveai'
    evaluator --help
    flatland-demo --help
    flatland-evaluator --help
    flatland-trajectory-evaluate --help
    flatland-trajectory-generate-from-policy --help

[testenv:benchmarks]
platform = linux|linux2|darwin
deps =
    -r requirements-dev.txt
set_env =
    BENCHMARK_EPISODES_FOLDER = {tox_root}/episodes
commands =
    python --version
    pytest -s benchmarks/benchmark_episodes.py
